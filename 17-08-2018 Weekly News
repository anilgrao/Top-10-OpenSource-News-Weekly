
## News Links:

1.	Tesla Self driving Open source  - Elon Musk Plans To Open Source Tesla Software Code
2.	TIBCO Flogo Edge  -  A Lightweight Runtime for Edge Computing released
3.	Oracle Graphpipe AI  -  open sources Graphpipe to standardize machine learning model deployment
4.	NVidia Turing GPU - Debuts AI-Ready Turing GPUs, with Real-Time Ray Tracing
5.	SalesForce Einstein ML - Plans to open-source the technology behind its Einstein machine-learning services
6.	IBM ZOWE mainframe OS  - OPEN SOURCE PROJECT - FAST, SIMPLE, FAMILIAR Z/OS DEVELOPMENT
7.	Amazon Alexa SDK - open sources Alexa ‘auto’ SDK for cars
8.	Security scan Github - Sonatype offers developers free tool on GitHub
9.	TSS ESAPI HW security  - Infineon enables open source HW Security
10.	Hollywood Goes Open Source - Collaborates With Linux Foundation – Establish Academy Software Foundation(ASF)!


## Detailed:


## Elon Musk Plans To Open Source Tesla Software Code
https://fossbytes.com/elon-musk-tesla-open-source-code/
August 13, 2018
One of the biggest advantages of open sourcing your software is allowing the independent security researchers to access the code and spot the vulnerabilities that might go unnoticed during the internal auditing.
A relatively newer area that’s increasingly witnessing security threats is the world of connected cars and self-driving vehicles.
To make things more secure, Tesla CEO Elon Musk has hinted at the possibility of open sourcing Tesla software code for a “safe self-driving future for all.”
Great Q&A @defcon last night. Thanks for helping make Tesla & SpaceX more secure! Planning to open-source Tesla vehicle security software for free use by other car makers. Extremely important to a safe self-driving future for all.
12:12 AM - Aug 12, 2018
The past track record of Tesla hasn’t been very impressive when it comes to following the open source norms. After lots of criticism, just earlier this year in May, Tesla announced its plans to open source some part of the code of its software that used many GPL-licensed technologies.
We don’t know yet if Elon Musk really wishes to act well on his promise and boost the security of connected cars in the process. In the long run, it’s also expected to benefit Tesla from a marketing viewpoint as Musk can boast of a better security standard as compared to others.
In the past, we’ve come across incidents of Tesla becoming a target of hackers and this step could turn out to be an encouraging one.
For more related stories and interesting development, keep reading Fossbytes.





## Project Flogo: A Lightweight Runtime for Edge Computing
https://thenewstack.io/project-flogo-a-lightweight-runtime-for-edge-computing/
13 Aug 2018 8:46am, by Janakiram MSV
The rise of edge computing marks the beginning of the next wave for enterprise Internet of Things platforms. Major public cloud providers — AWS, Google, and Microsoft — have extended their IoT platforms to the edge. For customers, edge computing is an extension of the public cloud. They get micro versions of cloud services including device management, machine-to-machine communication, authentication & authorization along with core compute services that are often delivered through containers and functions.
AWS Greengrass, Azure IoT Edge, and Google Cloud IoT Edge extend the IoT platform services to the edge. But these services are tightly coupled with their respective cloud platform services. There is a need for cloud-agnostic, platform-agnostic edge computing platforms that customers can deploy on-prem.
Project Flogo from TIBCO is a lightweight edge computing platform that is not tied to any specific public cloud platform. It’s an open source project developed with portability in mind. Since it is primarily written in Golang, the runtime can be deployed across a variety of environments. Project Flogo can run in a data center dominated by x86 servers running Kubernetes or a miniature Raspberry Pi Zero based on an ARM CORTEX processor.
Unlike other edge computing platforms, Project Flogo enjoys an extremely compact footprint. It is up to 20 to 50 times lighter than Node.js and Java Dropwizard runtimes. The binary required to execute Project Flogo applications is only 3.3Mb.
TIBCO built Project Flogo based on event-driven and serverless computing models. The platform is seamlessly integrated with mainstream serverless platforms such as AWS Lambda.
A Developer’s View of Project Flogo
Project Flogo is a no-code platform built on the lines of Node-Red. Developers familiar with Node-Red will be able to instantly relate to the tool. But Flogo is fundamentally different from Node-Red in terms of execution environment and runtime. To run Node-Red nodes, the deployment platform should have Node-Red installed. With Flogo, there are absolutely no expectations from the target environment. The binary emitted by Flogo can run like a native x86 or ARM executable with no dependencies whatsoever.
When building the apps on Flogo, developers either deal with the Web UI or CLI. Flogo apps are modeled as flows, which are declarations written in Domain Specific Language (DSL) based on JSON.
Instead of parsing and executing the flows dynamically at run-time, Flogo apps embed the flows within the binaries which are stand-alone. While developers need to compile the binary each time they change the flow, the advantage lies in the compact size of the resulting binary. The compiled binary is stand-alone, portable, and a self-contained entity with no dependencies. This is the biggest benefit of Project Flogo. These lightweight binaries can be easily pushed to the target environments through modern CI/CD tools.
Once a flow is developed and deployed, it can be invoked through a variety of triggers. Triggers in Flogo are wired to inbound and outbound channels such as REST, MQTT, CoAP, Kafka Topics, Cron Jobs, or even parameters sent directly via the CLI.
When a flow is executed, it starts listening for the triggers defined in the declaration. For example, an MQTT trigger will subscribe to an existing topic and waits for the publishers to send a message. Similarly, a REST trigger will synchronously wait on a specific port for an HTTP request to arrive.
So, what happens when a trigger is fired within a flow? A series of actions will take place either in a sequence or in a parallelized fashion. These actions are available as activities in Flogo. Activities do the heavy-lifting by processing the inbound messages came via triggers. For example, an activity might invoke Twilio API to send out a text message. Another activity may load a TensorFlow model to find an anomaly in the sensor telemetry. Project Flogo comes with over a dozen predefined activities that can be instantly included in the flows. Developers can also create custom activities in Golang and wire them with their flows.
Since Project Flogo is an event-driven platform, we can invoke the flows in response to external events. An AWS Lambda activity can be used to invoke existing Lambda functions.
But the serverless capabilities of Project Flogo go beyond the invocation of functions. The flows can target AWS Lambda. With AWS Lambda supporting Golang natively, Project Flogo flows can be packaged and deployed as Lambda functions. The combination of Flogo CLI and AWS CLI can be used to automate the deployment of functions.
Getting Started with Project Flogo
Project Flogo can be accessed either through a web interface or command line. The easiest way to get started is to pull the Docker image of Project Flogo.
Below are the simple steps to access the Flogo web UI.
$ docker run -it -p 3303:3303 flogo/flogo-docker:latest eula-accept
Wait for the image to get pulled and initialization to complete. The terminal will show the below output indicating that the platform is ready.
We are now ready to access the web UI. Hitting http://localhost:3303 will show the console:
Feel free to explore the sample application that comes with a few flows.
You can also install Flogo CLI through three simple steps.
1) Download Golang from https://golang.org and follow the instructions to configure the development environment. Make sure that GOPATH and GOBIN environment variables are correctly set.
2) Install Golang Dep tool to manage the dependency. Run the below command to configure the tool.
$ curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh
3) Finally, install Flogo CLI with the below command:
$ go get -u github.com/TIBCOSoftware/flogo-cli/...
If everything is installed and configured correctly, Flogo CLI should work.
In an upcoming article, I will walk you through steps in building and deploying an end-to-end Flogo application that can run on an edge computing device.





## Oracle open sources Graphpipe to standardize machine learning model deployment
https://techcrunch.com/2018/08/15/oracle-open-sources-graphpipe-to-standardize-machine-learning-model-deployment/
Oracle, a company not exactly known for having the best relationship with the open source community, is releasing a new open source tool today called Graphpipe, which is designed to simplify and standardize the deployment of machine learning models.
The tool consists of a set of libraries and tools for following the standard.
Vish Abrams, whose background includes helping develop OpenStack at NASA and later helping launch Nebula, an OpenStack startup in 2011, is leading the project. He says as his team dug into the machine learning workflow, they found a gap. While teams spend lots of energy developing a machine learning model, it’s hard to actually deploy the model for customers to use. That’s where Graphpipe comes in.
He points out that it’s common with newer technologies like machine learning for people to get caught up in the hype. Even though the development process keeps improving, he says that people often don’t think about deployment.
“Graphpipe is what’s grown out of our attempt to really improve deployment stories for machine learning models, and to create an open standard around having a way of doing that to improve the space,” Abrams told TechCrunch.
As Oracle dug into this, they identified three main problems. For starters, there is no standard way to serve APIs, leaving you to use whatever your framework provides. Next, there is no standard deployment mechanism, which leaves developers to build custom ones every time. Finally, they found existing methods leave performance as an afterthought, which in machine learning could be a major problem.
“We created Graphpipe to solve these three challenges. It provides a standard, high-performance protocol for transmitting tensor data over the network, along with simple implementations of clients and servers that make deploying and querying machine learning models from any framework a breeze,” Abrams wrote in a blog post announcing the release of Graphpipe.
The company decided to make this a standard and to open source it to try and move machine learning model deployment forward. “Graphpipe sits on that intersection between solving a business problems and pushing the state of the art forward, and I think personally, the best way to do that is by have an open source approach. Often, if you’re trying to standardize something without going for the open source bits, what you end up with is a bunch of competing technologies,” he said.
Abrams acknowledged the tension that has existed between Oracle and the open source community over the years, but says they have been working to change the perception recently with contributions to Kubernetes and Oracle FN, their open source Serverless Functions Platform as examples. Ultimately he says, if the technology is interesting enough, people will give it a chance, regardless of who is putting it out there. And of course, once it’s out there, if a community builds around it, they will adapt and change it as open source projects tend to do. Abrams hopes that happens.
“We care more about the standard becoming quite broadly adopted, than we do about our particular implementation of it because that makes it easier for everyone. It’s really up to the community decide that this is valuable and interesting.” he said.
Graphpipe is available starting today on the Oracle GitHub Graphpipe page.





## Nvidia Debuts AI-Ready Turing GPUs, with Real-Time Ray Tracing
https://thenewstack.io/nvidia-debuts-ai-ready-turing-gpus-with-real-time-ray-tracing/
GPU Manufacturer Nvidia has introduced a new chip architecture designed specifically for artificial intelligence deep learning work. The GPUs, dubbed Turing, also will be able to do real-time ray-tracing, a long sought-after capability for the $250 billion visual effects industry.
“This fundamentally changes how computer graphics will be done,” said Nvidia CEO Jensen Huang, during a Monday keynote at the SIGGRAPHprofessional graphics conference in Vancouver.
Huang touted this new, eighth generation, GPU architecture as the most significant advance since the company’s CUDA architecture, which was introduced in 2006. The company previewed a line of new GPU cards built on this design, the Quadro RTX 5000, 6000, and 8000, which will be available by the end of the year. It also revealed a reference architecture for the visual effects industry, the Quadro RTX Server, and released an open source a Material Definition Language software development kit, for mapping physical objects into rendering applications.
The Turing architecture is the result of 10,000 engineer-years of development, according to the company. It features a set of “RT cores” designed specifically accelerate ray-tracing — or the ability to simulate the trajectory that light and sound waves take in relation to the viewer actual perspective.
The company has estimated that the new architecture initially accelerates real-time ray tracing operations by 25x compared to the previous generation of GPUs, and by 30x over the speed of CPUs. To demonstrate this architecture, Huang showed how a Star Wars-themed Reflections ray-tracing demo can now run on a single Turing GPU, contrasting to an earlier demo that required a $70,000 DGX Station equipped with four Volta GPUs.
Huang boasted that Four 8-GPU RTX Servers should be able to do the rendering work of 240 dual-core servers, consuming 1/11th the power. This could reduce the time it takes to build out an animated shot to an hour, down from five or six hours.
“It’s going to completely change how people do film,” he said.
Turing also includes a set of “Tensor Cores,” for AI inferencing work. A single GPU can provide up to provide up to 500 trillion tensor operations a second. Important for deep learning work, tensors are data structures of related numbers that can be calculated against (much like matrices and vectors).
During the keynote, Huang explained how this muscle could be used to power deep learning operations for the visual effects industry: “At some point you can use AI or some heuristics to figure out what are the missing dots and how should we fill it all in, and it allows us to complete the frame a lot faster than we otherwise could.”
Nvidia has found support for Turing from system makers such as Dell EMC, HP, Inc., Hewlett Packard Enterprise, Lenovo, Fujitsu, and SuperMicro. Two dozen independent software vendors (ISVs) in the visual effects industry have also pledged support.






## Salesforce plans to open-source the technology behind its Einstein machine-learning services
https://www.geekwire.com/2018/salesforce-plans-open-source-technology-behind-einstein-machine-learning-services/
The Salesforce West Building in San Francisco. (Salesforce Photo)
Salesforce is open-sourcing the method it has developed for using machine-learning techniques at scale — without mixing valuable customer data — in hopes other companies struggling with data science problems can benefit from its work.
The company plans to announce Thursday that TransmogrifAI, which is a key part of the Einstein machine-learning services that it believes are the future of its flagship Sales Cloud and related services, will be available for anyone to use in their software-as-a-service applications. Consisting of less than 10 lines of code written on top of the widely used Apache Spark open-source project, it is the result of years of work on training machine-learning models to predict customer behavior without dumping all of that data into a common training ground, said Shubha Nabar, senior director of data science for Salesforce Einstein.
“Data scientists are focused on most customer-facing issues, but there are other issues in the business where machine-learning could transform how a business operates,” Nabar said. The problem is that data scientists are expensive, and while developers aren’t exactly cheap, companies need to hire them anyway and they can implement something like TransmogrifAI without having to learn how to do machine learning at scale within tricky constraints, she said.
A classic running gag in the beloved Calvin and Hobbes comic strip — a series of drawings printed in things called newspapers once upon a time — was the transmogrifier, a cardboard box that could transform a boy and his stuffed tiger into anything they wanted to be. That’s a bit of the idea behind TransmogrifAI, which will allow developers to transform applications that might not be top of mind for their data scientists with machine-learning insights.
“There are too few data scientists, and they are working on the most important problems,” Nabar said.
In most cases, when you’re looking to train a machine-learning model, you throw all the data at your disposal at it in hopes of determining patterns. But Salesforce’s customers are pretty paranoid about having the data sets mixed together, Nabar said, and so the company had to figure out a way to train its models with more limited data sets.
As befits a company like Salesforce, the project is primarily concerned with helping companies predict outcomes in their sales pipelines by automating a lot of the work that is usually done by an expensive data scientist. Figuring out why a customer bailed at a certain stage of the process allows companies to refine their sales tactics over time, and the companies in a given market that figure this out faster than their competitors can start to get an edge on the competition.
[Editor’s Note: Salesforce is a GeekWire annual sponsor. This post was updated to clarify the size of the codebase for the project.]




## OPEN SOURCE PROJECT ZOWE: FAST, SIMPLE, FAMILIAR Z/OS DEVELOPMENT
https://www.thegreengrid.org/en/newsroom/blog/open-source-project-zowe-fast-simple-familiar-zos-development
15 August, 2018 - Barry Baker - IBM
The IT landscape is evolving at a fast pace. Organizations continue to digitally transform to better serve the demands of their customers and differentiate themselves from their competitors. Many of these businesses have a mainframe as an essential asset at the heart of their digital transformation, and to drive the business. IBM Z mainframe strengths — security, availability, performance, data integrity and scalability – were validated in a recent Linux Foundation Open Mainframe Project survey as to why it’s the platform for some of the most important production workloads in the world.
At the same time, developers have risen in influence in shaping IT environments, and choosing open source technologies, services and APIs to respond to the pace of change to speed applications and services to market. Flexibility, agility and speed are key:  Single platforms are out, multi-platforms and multiclouds are in.
AND SO WE BRING THE TWO WORLDS TOGETHER WITH THE ANNOUNCEMENT OF ZOWE. ZOWE IS A NEW, AND THE FIRST OPEN SOURCE FRAMEWORK FOR Z/OS, AND PROVIDES SOLUTIONS FOR DEVELOPMENT AND OPERATIONS TEAMS TO SECURELY MANAGE, CONTROL, SCRIPT AND DEVELOP ON THE MAINFRAME LIKE ANY OTHER CLOUD PLATFORM. LAUNCHED IN A COLLABORATION OF INITIAL CONTRIBUTORS IBM, CA TECHNOLOGIES AND ROCKET SOFTWARE, AND WITH THE SUPPORT OF THE OPEN MAINFRAME PROJECT, THE GOAL IS TO BRING TOGETHER INDUSTRY EXPERTS TO DRIVE INNOVATION FOR THE COMMUNITY OF NEXT-GENERATION MAINFRAME DEVELOPERS WHETHER OR NOT THEY HAVE PLATFORM EXPERIENCE. ZOWE PROMOTES A FASTER TEAM ON-RAMP TO PRODUCTIVITY, COLLABORATION, KNOWLEDGE SHARING AND COMMUNICATION.
We believe it takes a strong ecosystem, and not a single tool provider that can “do it all”, consistent with what is seen on all other vibrant platforms including cloud. We see a future where the mainframe’s development and operations teams can have a simple, transparent and rapidly assembled workflow of options, delivered by different vendors and contributors—all to speed value to market.
IBM’s initial contribution to project Zowe is an extensible z/OS framework that provides REST-based services or APIs that will allow you to rapidly use new technology, tools, languages and modern workflows with z/OS. Today IBM is contributing z/OS Explorer Core, where developers get a set of discoverable foundational services or building blocks which will be used across all aspects of Zowe. IBM will continue to invest in the open source environment, through Zowe and broader open source initiatives. Learn more in the Zowe Statement of Direction.
In addition to IBM’s contribution, Rocket Software will provide a web user interface and CA will provide a Command Line Interface.
You can get started today – in discussions on slack, and with new information and early code. Join us now at zowe.org.
The post Open source project Zowe: Fast, simple, familiar z/OS development appeared first on IBM IT Infrastructure Blog.




## Amazon open sources Alexa ‘auto’ SDK for cars
https://www.computerweekly.com/blog/Open-Source-Insider/Amazon-open-sources-Alexa-auto-SDK-for-cars
Cloud giant Amazon has announced the open source release of its Alexa Auto SDK (Software Development Kit).
The news comes from the company’s Amazon Voice Services (AVS) division.
The SDK is provided for software application developers working with automobile manufacturers in order for them to be able to build the Alexa-controlled intelligent assistant applications (and related smaller functions) into software systems intended to be deployed inside working cars. 
As detailed on TechTarget, AVS and Alexa were first introduced with Echo, the company’s intelligent speaker, which enables voice interaction with various systems.
Alexa’s main competitors are Google Assistant, Apple Siri and Microsoft Cortana.
According to Amazon AVS, the Alexa Voice Service (AVS) enables [developers] to access cloud-based Alexa capabilities with the support of AVS APIs, hardware kits, software tools and documentation.
Voice-forward
“We simplify building ‘voice-forward’ products by handling complex speech recognition and natural language understanding in the cloud, reducing your development costs and accelerating your time to market,” notes Amazon AVS.
What’s inside the SDK?
In terms of components and functionality found in the SDK itself, it will provide a runtime engine to enable data communication interactions with Alexa itself.
The SDK will also provide the necessary interfaces that developers will need to work with audio input controls and media playback… but the SDK is also intended to be potentially used to power the creation of voice-driven (let’s use Amazon’s term and say voice-forward) app functions that could include other automated operations inside a car such as air conditioning, electric windows and other ‘custom skills’.
According to Amazon, “The Alexa Auto SDK includes core Alexa functionality, such as speech recognition and synthesis, and other capabilities such as streaming media, controlling smart home devices, notifications, weather reports and tens-of-thousands of custom skills.”
Additionally, the SDK provides the hooks required to connect to a wake word engine, local media player, local phone and local navigation system.
The SDK is available on GitHub.




## Sonatype offers developers free security scan tool on GitHub
https://techcrunch.com/2018/08/14/sonatype-now-offers-free-open-source-vulnerability-scans-to-github-users/
Sonatype helps enterprises identify and remediate vulnerabilities in open source library dependencies and release more secure code. Today, they announced a free tool called DepShield that offers a basic level of protection for GitHub developers.
The product is actually two parts. For starters, Sonatype has a database of open source dependency vulnerabilities called OSS Index. The company gathers this information from a variety of public sources, says Sonatype CEO Wayne Jackson. While it isn’t as highly curated as the company’s commercial offerings, it does offer a layer of protection that most individual developers or small shops wouldn’t normally have access to.
After a developer installs DepShield, it checks a code commit in GitHub  against the known vulnerabilities in the OSS Index with recommendations on how to proceed. The company’s commercial offerings includes a policy engine to automate remediation. The free version simply lets developers know if there are issues, and they can go back and fix them if need be.
“What DepShield and OSS Index are doing is allowing the developers at the front lines to be able to see what’s happening inside their applications and fix the vulnerabilities directly,” Jackson said.
Vulnerability listed in OSS Index. Screenshot: Sonatype
As for the differences between the commercial and free products, Jackson say it’s a matter of scale. “The way you manage a single application or handful of applications as a developer is different than how you might approach it if you’re a CISO or a governance organization for thousands of applications,” he explained. The latter requires a higher level of automation than the former because of the sheer number of applications involved.
DepShield offers the 28 million developers using GitHub access to a baseline level of protection by identifying a set of known vulnerabilities in their applications before they make them public. Jackson says that GitHub’s role is evolving. Today, it’s not only a tool for committing your code, it’s also become a place to do issue tracking and code reviews, and he believes that as such, a product like DepShield is a natural fit.
Known issues list DepShield. Screenshot: Sonatype
DepShield is available starting today in the Security section of the GitHub Marketplace and developers can download and install it for free.
Sonatype, which is based in Maryland, launched in 2008 and has raised almost $75 million, according to data on Crunchbase. Its most recent funding round was in 2016 for $30 million. Microsoft acquired GitHub in June for $7.5 billion.




## Infineon enables open source TSS ESAPI layer
https://www.electronicsweekly.com/news/business/infineon-enables-open-source-tss-esapi-layer-2018-08/
Infineon  has enabled a new open source software stack which aims to make work easier for developers who want to use the Trusted Platform Module (TPM) 2.0 – a standardized hardware-based security solution for securing industrial, automotive and other applications such as network equipment.
This is the first open source TPM middleware that complies with the Software Stack (TSS) Enhanced System API (ESAPI) specification of the Trusted Computing Group .
“The ease of integration on Linux and other embedded platforms that comes with the release of the TPM 2.0 ESAPI stack speeds up the adoption of TPM 2.0 in embedded systems such as network equipment and industrial systems,” says Gordon Muehl, Global CTO Security at Huawei.
“We are currently seeing great interest in enhancing the security of IoT, IIoT, Industry 4.0 and automotive applications,” says Michael Roeder, Manager Technology Engineering and Services at Avnet Silica,  “the availability of the open source TSS ESAPI layer simplifies the integration of TPM 2.0 in all kinds of applications.”
Making the TSS ESAPI layer available to everyone is part of Infineon´s commitment to ease the integration and wide adoption of strong security. This is further supported by security experts and industry leaders of the Infineon Security Partner Network (ISPN). The ISPN offers a wide variety of software libraries meeting the requirements of different applications and target platforms.
Infineon funded the development of the ESAPI by Fraunhofer Institute for Secure Information Technology SIT, a long-term partner of Infineon in this field. The Infineon-funded ESAPI layer is based on the SAPI layer developed by Intel Corporation. It includes a new layer of API functions to simplify the use and integration of the TPM. It facilitates establishing a connection with the TPM through an application, secured communication between the host CPU and the TPM, and authorization using message authentication codes (HMAC).
Based on the ESAPI layer, the stack includes support for OpenSSL. It can use the Infineon OPTIGA™ TPM to protect device communication secured with SSL/TLS via a standardized interface by deploying TPM 2.0 as a secured key store for OpenSSL. It thus protects the keys from vulnerabilities like the famous Heartbleed bug.
The TSS stack and ESAPI layer are published under the permissive 2-clause BSD license, which provides high flexibility and increases adoption.
The ESAPI has been designed and validated by a wide community to achieve a high level of quality and stability, as is required in modern embedded and IoT systems.
With industrial and automotive customers in mind, the code was developed using industry standards, continuous integration and testing, a thorough two-person review process, and static code analyzers like clang and Coverity.
In addition, the stack was tested and evaluated on Infineon OPTIGA™ TPM SLB 9670 with the latest TPM specifications. Future enhancements will include support for Cryptsetup/LUKS disk encryption and a version featuring ESAPI support for TPM tools.
“With the release of the TSS, we have reached a milestone for providing enhanced protection of embedded systems in areas such as industry, automotive, or smart home using the TPM 2.0,” says Andreas Fuchs, project leader at Fraunhofer SIT.
Application developers can use the OPTIGA TPM SLB 9670 Iridium boards offered by Infineon and download the TSS code via Github to get started right away. Source code packages for the Infineon AURIX™ as well as for Arduino microcontrollers will be released in due course.




## Hollywood Goes Open Source; Collaborates With Linux Foundation
https://fossbytes.com/hollywood-open-source-linux-foundation/
August 11, 2018
The Academy of Motion Picture Arts and Sciences which is best known for organizing the Oscars has announced its love for open source tech. It has joined hands with the Linux Foundation to establish the Academy Software Foundation (ASWF).
The objective of ASWF is to increase the quality and quantity of contributions to the entertainment industry through open-source projects. It will provide a neutral platform to facilitate cross-project efforts, a common built and test infrastructure.
The founding members behind this initiative include big names like Google, Walt Disney Studios, Cisco, DreamWorks, Intel, SideFX, Blue Sky Studios, Epic Games, Animal Logic, etc.
Nearly 84% of Hollywood already uses open source software to throw in visual effects and animation in film production. But all of that work has been accomplished in isolation by different companies till now.
Also, licensing such work has proved to be a challenge, partly because studios didn’t know which license they should choose. The foundation would probably try to solve this problem through shared licensing templates, and also look after the management of relevant open source projects.
With the Academy Software Foundation, open source developers in the motion picture and media space will now be able to join their efforts and bring the next wave of innovation through interoperability.

## __END__


